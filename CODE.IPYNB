{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "adf72242",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_mlp_xgb_ensemble_complete.py\n",
    "# Complete pipeline: Patient Treatment Classification with Deep MLP + XGBoost + RF Ensemble\n",
    "\n",
    "import os\n",
    "import json\n",
    "import joblib\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, cross_validate\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    roc_auc_score, confusion_matrix, classification_report\n",
    ")\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import VotingClassifier, RandomForestClassifier\n",
    "\n",
    "import xgboost as xgb\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30b8ef25",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "<>:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "C:\\Users\\rampr\\AppData\\Local\\Temp\\ipykernel_49500\\923507166.py:1: SyntaxWarning: invalid escape sequence '\\P'\n",
      "  \"C:\\PERSONAL\\PATIENT TEST CLASSIFICATION\\DATASET.csv\"\n"
     ]
    }
   ],
   "source": [
    "\"C:\\PERSONAL\\PATIENT TEST CLASSIFICATION\\DATASET.csv\"\n",
    "DATA_PATH = r\"C:\\PERSONAL\\PATIENT TREATMENT CLASSIFICATION\\DATASET.csv\"# change to your downloaded CSV path\n",
    "ARTIFACT_DIR = r\"C:\\PERSONAL\\PATIENT TREATMENT CLASSIFICATION/artifacts_patient_treatment\"\n",
    "\n",
    "RANDOM_STATE = 42\n",
    "TEST_SIZE = 0.2\n",
    "VAL_SIZE = 0.2  # from remaining train\n",
    "\n",
    "os.makedirs(ARTIFACT_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "380b47c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "PATIENT TREATMENT CLASSIFICATION - ENSEMBLE PIPELINE\n",
      "======================================================================\n",
      "\n",
      "Loaded dataset: 4412 rows, 11 columns\n",
      "Columns: ['HAEMATOCRIT', 'HAEMOGLOBINS', 'ERYTHROCYTE', 'LEUCOCYTE', 'THROMBOCYTE', 'MCH', 'MCHC', 'MCV', 'AGE', 'SEX', 'SOURCE']\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 1. LOAD DATA\n",
    "# ===================================================================\n",
    "print(\"=\"*70)\n",
    "print(\"PATIENT TREATMENT CLASSIFICATION - ENSEMBLE PIPELINE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "print(f\"\\nLoaded dataset: {df.shape[0]} rows, {df.shape[1]} columns\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")\n",
    "\n",
    "df.to_csv(os.path.join(ARTIFACT_DIR, \"raw_data_snapshot.csv\"), index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "558cb705",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXPLORATORY DATA ANALYSIS\n",
      "\n",
      "Target column: SOURCE\n",
      "Class distribution:\n",
      "SOURCE\n",
      "out    2628\n",
      "in     1784\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 2. EDA AND PLOTS\n",
    "# ===================================================================\n",
    "\n",
    "print(\"EXPLORATORY DATA ANALYSIS\")\n",
    "\n",
    "TARGET_COL=\"SOURCE\"\n",
    "\n",
    "with open(os.path.join(ARTIFACT_DIR, \"data_info.txt\"), \"w\") as f:\n",
    "    f.write(\"DATAFRAME INFO\\n\")\n",
    "    df.info(buf=f)\n",
    "    f.write(\"\\n\\nDESCRIBE (NUMERIC)\\n\")\n",
    "    f.write(df.describe(include=[np.number]).to_string())\n",
    "    f.write(\"\\n\\nDESCRIBE (ALL)\\n\")\n",
    "    f.write(df.describe(include=\"all\").to_string())\n",
    "\n",
    "# Class distribution\n",
    "print(f\"\\nTarget column: {TARGET_COL}\")\n",
    "print(\"Class distribution:\")\n",
    "print(df[TARGET_COL].value_counts())\n",
    "\n",
    "plt.figure(figsize=(6, 4))\n",
    "df[TARGET_COL].value_counts().plot(kind=\"bar\")\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ARTIFACT_DIR, \"class_distribution.png\"))\n",
    "plt.close()\n",
    "\n",
    "# Correlation heatmap\n",
    "numeric_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "if len(numeric_cols) > 1:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    corr = df[numeric_cols].corr()\n",
    "    sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\", square=True)\n",
    "    plt.title(\"Feature Correlation Heatmap\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ARTIFACT_DIR, \"corr_heatmap.png\"), dpi=150)\n",
    "    plt.close()\n",
    "\n",
    "# Histograms (first 10 numeric features)\n",
    "for col in numeric_cols[:10]:\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.histplot(df[col].dropna(), kde=True, bins=30)\n",
    "    plt.title(f\"Distribution of {col}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ARTIFACT_DIR, f\"hist_{col}.png\"))\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a782229",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "DATA SPLITTING\n",
      "======================================================================\n",
      "Target classes: ['in', 'out'] -> encoded as [0, 1]\n",
      "\n",
      "Train: 2823, Val: 706, Test: 883\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 3. TRAIN/VAL/TEST SPLIT WITH LABEL ENCODING\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"DATA SPLITTING\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "X = df.drop(columns=[TARGET_COL])\n",
    "y = df[TARGET_COL]\n",
    "\n",
    "# Encode target if string\n",
    "if y.dtype == \"O\" or isinstance(y.iloc[0], str):\n",
    "    le = LabelEncoder()\n",
    "    y_encoded = le.fit_transform(y)\n",
    "    class_names = le.classes_.tolist()\n",
    "    print(f\"Target classes: {class_names} -> encoded as {list(range(len(class_names)))}\")\n",
    "    joblib.dump(le, os.path.join(ARTIFACT_DIR, \"label_encoder.joblib\"))\n",
    "else:\n",
    "    y_encoded = y.values\n",
    "    class_names = sorted(y.unique().tolist())\n",
    "    le = None\n",
    "\n",
    "X_train_full, X_test, y_train_full, y_test = train_test_split(\n",
    "    X, y_encoded, test_size=TEST_SIZE, random_state=RANDOM_STATE, stratify=y_encoded\n",
    ")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train_full, y_train_full, test_size=VAL_SIZE,\n",
    "    random_state=RANDOM_STATE, stratify=y_train_full\n",
    ")\n",
    "\n",
    "print(f\"\\nTrain: {len(y_train)}, Val: {len(y_val)}, Test: {len(y_test)}\")\n",
    "\n",
    "# Save splits\n",
    "for split_name, X_split, y_split in [\n",
    "    (\"train\", X_train, y_train),\n",
    "    (\"val\", X_val, y_val),\n",
    "    (\"test\", X_test, y_test),\n",
    "]:\n",
    "    split_df = X_split.copy()\n",
    "    split_df[TARGET_COL] = y_split\n",
    "    split_df.to_csv(os.path.join(ARTIFACT_DIR, f\"{split_name}_split.csv\"), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b5a36d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Numeric features: 9\n",
      "Categorical features: 1\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 4. PREPROCESSING PIPELINE\n",
    "# ===================================================================\n",
    "numeric_features = X.select_dtypes(include=[np.number]).columns.tolist()\n",
    "categorical_features = X.select_dtypes(exclude=[np.number]).columns.tolist()\n",
    "\n",
    "print(f\"\\nNumeric features: {len(numeric_features)}\")\n",
    "print(f\"Categorical features: {len(categorical_features)}\")\n",
    "\n",
    "numeric_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ]\n",
    ")\n",
    "\n",
    "categorical_transformer = Pipeline(\n",
    "    steps=[\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"onehot\",\n",
    "         __import__(\"sklearn.preprocessing\").preprocessing.OneHotEncoder(\n",
    "             handle_unknown=\"ignore\"\n",
    "         ))\n",
    "    ]\n",
    ")\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features),\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0b156cd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "MODEL ARCHITECTURE\n",
      "======================================================================\n",
      "\n",
      "Training set class distribution:\n",
      "  Class 'in': 1142 samples (40.5%)\n",
      "  Class 'out': 1681 samples (59.5%)\n",
      "\n",
      "XGBoost scale_pos_weight: 0.68\n",
      "\n",
      "Ensemble models:\n",
      "  1. Deep MLP: 5 layers (512, 256, 128, 64, 32)\n",
      "  2. XGBoost: 500 trees, max_depth=4\n",
      "  3. Random Forest: 300 trees, balanced weights\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 5. BASE MODELS WITH CLASS IMBALANCE HANDLING\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"MODEL ARCHITECTURE\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Check class distribution\n",
    "unique, counts = np.unique(y_train, return_counts=True)\n",
    "print(\"\\nTraining set class distribution:\")\n",
    "for u, c in zip(unique, counts):\n",
    "    print(f\"  Class '{class_names[u]}': {c} samples ({c/len(y_train)*100:.1f}%)\")\n",
    "\n",
    "# Deep MLP\n",
    "mlp = MLPClassifier(\n",
    "    hidden_layer_sizes=(512, 256, 128, 64, 32),\n",
    "    activation=\"relu\",\n",
    "    solver=\"adam\",\n",
    "    alpha=5e-3,\n",
    "    batch_size=128,\n",
    "    learning_rate=\"adaptive\",\n",
    "    learning_rate_init=1e-4,\n",
    "    max_iter=600,\n",
    "    early_stopping=True,\n",
    "    n_iter_no_change=40,\n",
    "    validation_fraction=0.2,\n",
    "    random_state=RANDOM_STATE,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "# XGBoost with scale_pos_weight\n",
    "n_neg = counts[0]\n",
    "n_pos = counts[1]\n",
    "scale_weight = n_neg / n_pos if n_pos > 0 else 1.0\n",
    "print(f\"\\nXGBoost scale_pos_weight: {scale_weight:.2f}\")\n",
    "\n",
    "xgb_clf = xgb.XGBClassifier(\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    n_estimators=500,\n",
    "    max_depth=4,\n",
    "    learning_rate=0.03,\n",
    "    subsample=0.7,\n",
    "    colsample_bytree=0.7,\n",
    "    min_child_weight=3,\n",
    "    gamma=0.1,\n",
    "    reg_alpha=0.1,\n",
    "    reg_lambda=1.0,\n",
    "    scale_pos_weight=scale_weight,\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbosity=0\n",
    ")\n",
    "\n",
    "# Random Forest\n",
    "rf_clf = RandomForestClassifier(\n",
    "    n_estimators=300,\n",
    "    max_depth=10,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5,\n",
    "    max_features=\"sqrt\",\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1,\n",
    "    verbose=0\n",
    ")\n",
    "\n",
    "print(\"\\nEnsemble models:\")\n",
    "print(\"  1. Deep MLP: 5 layers (512, 256, 128, 64, 32)\")\n",
    "print(\"  2. XGBoost: 500 trees, max_depth=4\")\n",
    "print(\"  3. Random Forest: 300 trees, balanced weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b2645e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===================================================================\n",
    "# 6. ENSEMBLE WITH SMOTE\n",
    "# ===================================================================\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[\n",
    "        (\"deep_mlp\", mlp),\n",
    "        (\"xgboost\", xgb_clf),\n",
    "        (\"random_forest\", rf_clf)\n",
    "    ],\n",
    "    voting=\"soft\",\n",
    "    weights=[1.5, 2.0, 1.0],\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "ensemble_pipeline = ImbPipeline(\n",
    "    steps=[\n",
    "        (\"preprocessor\", preprocessor),\n",
    "        (\"smote\", SMOTE(random_state=RANDOM_STATE, k_neighbors=5)),\n",
    "        (\"ensemble\", voting_clf)\n",
    "    ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d0ad3a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "TRAINING\n",
      "======================================================================\n",
      "\n",
      "Training ensemble with SMOTE oversampling...\n",
      "✓ Model saved\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 7. TRAINING\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"TRAINING\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nTraining ensemble with SMOTE oversampling...\")\n",
    "\n",
    "ensemble_pipeline.fit(X_train, y_train)\n",
    "\n",
    "joblib.dump(ensemble_pipeline, os.path.join(ARTIFACT_DIR, \"ensemble_pipeline.joblib\"))\n",
    "print(\"✓ Model saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c1bfc50f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "INITIAL EVALUATION\n",
      "======================================================================\n",
      "\n",
      "TRAIN Metrics:\n",
      "  Accuracy : 0.8282\n",
      "  Precision: 0.8655\n",
      "  Recall   : 0.8424\n",
      "  F1       : 0.8538\n",
      "  ROC AUC  : 0.9131\n",
      "  Sensitivity ('out'): 0.8424\n",
      "  Specificity ('in'): 0.8074\n",
      "  False Positives: 220, False Negatives: 265\n",
      "  Confusion Matrix:\n",
      "  ['in', 'out']\n",
      "[[ 922  220]\n",
      " [ 265 1416]]\n",
      "\n",
      "VAL Metrics:\n",
      "  Accuracy : 0.7465\n",
      "  Precision: 0.8025\n",
      "  Recall   : 0.7625\n",
      "  F1       : 0.7820\n",
      "  ROC AUC  : 0.7961\n",
      "  Sensitivity ('out'): 0.7625\n",
      "  Specificity ('in'): 0.7228\n",
      "  False Positives: 79, False Negatives: 100\n",
      "  Confusion Matrix:\n",
      "  ['in', 'out']\n",
      "[[206  79]\n",
      " [100 321]]\n",
      "\n",
      "TEST Metrics:\n",
      "  Accuracy : 0.7271\n",
      "  Precision: 0.7902\n",
      "  Recall   : 0.7376\n",
      "  F1       : 0.7630\n",
      "  ROC AUC  : 0.8091\n",
      "  Sensitivity ('out'): 0.7376\n",
      "  Specificity ('in'): 0.7115\n",
      "  False Positives: 103, False Negatives: 138\n",
      "  Confusion Matrix:\n",
      "  ['in', 'out']\n",
      "[[254 103]\n",
      " [138 388]]\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 8. EVALUATION FUNCTION\n",
    "# ===================================================================\n",
    "def evaluate_split(name, model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    try:\n",
    "        y_proba = model.predict_proba(X)[:, 1]\n",
    "        auc = roc_auc_score(y_true, y_proba)\n",
    "    except Exception:\n",
    "        y_proba = None\n",
    "        auc = None\n",
    "\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    report = classification_report(y_true, y_pred, target_names=class_names,\n",
    "                                   output_dict=True, zero_division=0)\n",
    "\n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "\n",
    "    metrics = {\n",
    "        \"split\": name,\n",
    "        \"accuracy\": float(acc),\n",
    "        \"precision\": float(prec),\n",
    "        \"recall\": float(rec),\n",
    "        \"f1\": float(f1),\n",
    "        \"roc_auc\": float(auc) if auc is not None else None,\n",
    "        \"sensitivity\": float(sensitivity),\n",
    "        \"specificity\": float(specificity),\n",
    "        \"false_positives\": int(fp),\n",
    "        \"false_negatives\": int(fn),\n",
    "        \"confusion_matrix\": cm.tolist(),\n",
    "        \"classification_report\": report,\n",
    "    }\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ARTIFACT_DIR, f\"cm_{name}.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    print(f\"\\n{name} Metrics:\")\n",
    "    print(f\"  Accuracy : {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall   : {rec:.4f}\")\n",
    "    print(f\"  F1       : {f1:.4f}\")\n",
    "    if auc:\n",
    "        print(f\"  ROC AUC  : {auc:.4f}\")\n",
    "    print(f\"  Sensitivity ('{class_names[1]}'): {sensitivity:.4f}\")\n",
    "    print(f\"  Specificity ('{class_names[0]}'): {specificity:.4f}\")\n",
    "    print(f\"  False Positives: {fp}, False Negatives: {fn}\")\n",
    "    print(\"  Confusion Matrix:\")\n",
    "    print(f\"  {class_names}\")\n",
    "    print(cm)\n",
    "\n",
    "    return metrics\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"INITIAL EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "metrics_train = evaluate_split(\"TRAIN\", ensemble_pipeline, X_train, y_train)\n",
    "metrics_val = evaluate_split(\"VAL\", ensemble_pipeline, X_val, y_val)\n",
    "metrics_test = evaluate_split(\"TEST\", ensemble_pipeline, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6559e931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "THRESHOLD OPTIMIZATION\n",
      "======================================================================\n",
      "\n",
      "Tuning threshold on validation set:\n",
      "  Threshold 0.30: F1=0.8165, Acc=0.7606, Sens=0.8931, Spec=0.5649\n",
      "  Threshold 0.35: F1=0.8063, Acc=0.7550, Sens=0.8551, Spec=0.6070\n",
      "  Threshold 0.40: F1=0.7972, Acc=0.7507, Sens=0.8219, Spec=0.6456\n",
      "  Threshold 0.45: F1=0.8043, Acc=0.7663, Sens=0.8052, Spec=0.7088\n",
      "  Threshold 0.50: F1=0.7820, Acc=0.7465, Sens=0.7625, Spec=0.7228\n",
      "  Threshold 0.55: F1=0.7541, Acc=0.7238, Sens=0.7102, Spec=0.7439\n",
      "  Threshold 0.60: F1=0.7215, Acc=0.7025, Sens=0.6461, Spec=0.7860\n",
      "  Threshold 0.65: F1=0.6863, Acc=0.6827, Sens=0.5819, Spec=0.8316\n",
      "  Threshold 0.70: F1=0.6087, Acc=0.6303, Sens=0.4822, Spec=0.8491\n",
      "  Threshold 0.75: F1=0.5408, Acc=0.5935, Sens=0.4014, Spec=0.8772\n",
      "\n",
      "✅ Best threshold: 0.30 (F1=0.8165)\n",
      "\n",
      "======================================================================\n",
      "OPTIMIZED EVALUATION\n",
      "======================================================================\n",
      "\n",
      "VAL Metrics (threshold=0.30):\n",
      "  Accuracy : 0.7606\n",
      "  Precision: 0.7520\n",
      "  Recall   : 0.8931\n",
      "  F1       : 0.8165\n",
      "  ROC AUC  : 0.7961\n",
      "  Sensitivity ('out'): 0.8931\n",
      "  Specificity ('in'): 0.5649\n",
      "  False Positives: 124, False Negatives: 45\n",
      "  Confusion Matrix: ['in', 'out']\n",
      "[[161 124]\n",
      " [ 45 376]]\n",
      "\n",
      "TEST Metrics (threshold=0.30):\n",
      "  Accuracy : 0.7463\n",
      "  Precision: 0.7412\n",
      "  Recall   : 0.8821\n",
      "  F1       : 0.8056\n",
      "  ROC AUC  : 0.8091\n",
      "  Sensitivity ('out'): 0.8821\n",
      "  Specificity ('in'): 0.5462\n",
      "  False Positives: 162, False Negatives: 62\n",
      "  Confusion Matrix: ['in', 'out']\n",
      "[[195 162]\n",
      " [ 62 464]]\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 9. THRESHOLD OPTIMIZATION\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"THRESHOLD OPTIMIZATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "y_val_proba = ensemble_pipeline.predict_proba(X_val)[:, 1]\n",
    "\n",
    "thresholds = np.arange(0.3, 0.8, 0.05)\n",
    "best_threshold = 0.5\n",
    "best_f1 = 0.0\n",
    "\n",
    "print(\"\\nTuning threshold on validation set:\")\n",
    "for thresh in thresholds:\n",
    "    y_pred_thresh = (y_val_proba >= thresh).astype(int)\n",
    "    f1_thresh = f1_score(y_val, y_pred_thresh)\n",
    "    acc_thresh = accuracy_score(y_val, y_pred_thresh)\n",
    "    cm_thresh = confusion_matrix(y_val, y_pred_thresh)\n",
    "    \n",
    "    tn, fp, fn, tp = cm_thresh.ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    print(f\"  Threshold {thresh:.2f}: F1={f1_thresh:.4f}, Acc={acc_thresh:.4f}, \"\n",
    "          f\"Sens={sensitivity:.4f}, Spec={specificity:.4f}\")\n",
    "    \n",
    "    if f1_thresh > best_f1:\n",
    "        best_f1 = f1_thresh\n",
    "        best_threshold = thresh\n",
    "\n",
    "print(f\"\\n✅ Best threshold: {best_threshold:.2f} (F1={best_f1:.4f})\")\n",
    "\n",
    "# Re-evaluate with optimized threshold\n",
    "def evaluate_with_threshold(name, model, X, y_true, threshold):\n",
    "    y_proba = model.predict_proba(X)[:, 1]\n",
    "    y_pred = (y_proba >= threshold).astype(int)\n",
    "    \n",
    "    auc = roc_auc_score(y_true, y_proba)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, zero_division=0)\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    \n",
    "    tn, fp, fn, tp = cm.ravel()\n",
    "    sensitivity = tp / (tp + fn) if (tp + fn) > 0 else 0\n",
    "    specificity = tn / (tn + fp) if (tn + fp) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{name} Metrics (threshold={threshold:.2f}):\")\n",
    "    print(f\"  Accuracy : {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall   : {rec:.4f}\")\n",
    "    print(f\"  F1       : {f1:.4f}\")\n",
    "    print(f\"  ROC AUC  : {auc:.4f}\")\n",
    "    print(f\"  Sensitivity ('{class_names[1]}'): {sensitivity:.4f}\")\n",
    "    print(f\"  Specificity ('{class_names[0]}'): {specificity:.4f}\")\n",
    "    print(f\"  False Positives: {fp}, False Negatives: {fn}\")\n",
    "    print(f\"  Confusion Matrix: {class_names}\")\n",
    "    print(cm)\n",
    "    \n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title(f\"CM - {name} (optimized threshold={threshold:.2f})\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(ARTIFACT_DIR, f\"cm_{name}_optimized.png\"))\n",
    "    plt.close()\n",
    "    \n",
    "    return {\n",
    "        \"split\": name,\n",
    "        \"threshold\": float(threshold),\n",
    "        \"accuracy\": float(acc),\n",
    "        \"precision\": float(prec),\n",
    "        \"recall\": float(rec),\n",
    "        \"f1\": float(f1),\n",
    "        \"roc_auc\": float(auc),\n",
    "        \"sensitivity\": float(sensitivity),\n",
    "        \"specificity\": float(specificity),\n",
    "        \"false_positives\": int(fp),\n",
    "        \"false_negatives\": int(fn),\n",
    "        \"confusion_matrix\": cm.tolist()\n",
    "    }\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"OPTIMIZED EVALUATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "metrics_val_opt = evaluate_with_threshold(\"VAL\", ensemble_pipeline, X_val, y_val, best_threshold)\n",
    "metrics_test_opt = evaluate_with_threshold(\"TEST\", ensemble_pipeline, X_test, y_test, best_threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d554c239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "CROSS-VALIDATION\n",
      "======================================================================\n",
      "\n",
      "5-Fold Cross-Validation Results:\n",
      "  mean_train_accuracy: 0.8231\n",
      "  std_train_accuracy: 0.0134\n",
      "  mean_val_accuracy: 0.7385\n",
      "  std_val_accuracy: 0.0072\n",
      "  mean_train_f1: 0.8493\n",
      "  std_train_f1: 0.0121\n",
      "  mean_val_f1: 0.7764\n",
      "  std_val_f1: 0.0102\n",
      "  mean_val_roc_auc: 0.8023\n",
      "  std_val_roc_auc: 0.0068\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 10. CROSS-VALIDATION\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"CROSS-VALIDATION\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=RANDOM_STATE)\n",
    "cv_results = cross_validate(\n",
    "    ensemble_pipeline,\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    cv=cv,\n",
    "    scoring=[\"accuracy\", \"f1\", \"roc_auc\"],\n",
    "    return_train_score=True,\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "cv_summary = {\n",
    "    \"mean_train_accuracy\": float(np.mean(cv_results[\"train_accuracy\"])),\n",
    "    \"std_train_accuracy\": float(np.std(cv_results[\"train_accuracy\"])),\n",
    "    \"mean_val_accuracy\": float(np.mean(cv_results[\"test_accuracy\"])),\n",
    "    \"std_val_accuracy\": float(np.std(cv_results[\"test_accuracy\"])),\n",
    "    \"mean_train_f1\": float(np.mean(cv_results[\"train_f1\"])),\n",
    "    \"std_train_f1\": float(np.std(cv_results[\"train_f1\"])),\n",
    "    \"mean_val_f1\": float(np.mean(cv_results[\"test_f1\"])),\n",
    "    \"std_val_f1\": float(np.std(cv_results[\"test_f1\"])),\n",
    "    \"mean_val_roc_auc\": float(np.mean(cv_results[\"test_roc_auc\"])),\n",
    "    \"std_val_roc_auc\": float(np.std(cv_results[\"test_roc_auc\"])),\n",
    "}\n",
    "\n",
    "print(\"\\n5-Fold Cross-Validation Results:\")\n",
    "for key, val in cv_summary.items():\n",
    "    print(f\"  {key}: {val:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b9e1f498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "PIPELINE COMPLETE\n",
      "======================================================================\n",
      "\n",
      "✅ All artifacts saved to: C:\\PERSONAL\\PATIENT TREATMENT CLASSIFICATION/artifacts_patient_treatment\n",
      "\n",
      "Saved files:\n",
      "  - ensemble_pipeline.joblib (trained model)\n",
      "  - label_encoder.joblib\n",
      "  - metrics.json (all performance metrics)\n",
      "  - metadata.json\n",
      "  - confusion matrices (PNG)\n",
      "  - EDA plots (PNG)\n",
      "  - train/val/test splits (CSV)\n",
      "\n",
      "Ensemble combines:\n",
      "  - Deep MLP: 5 layers (512→256→128→64→32)\n",
      "  - XGBoost: 500 trees with class balancing\n",
      "  - Random Forest: 300 trees with balanced weights\n",
      "  - SMOTE oversampling for training balance\n",
      "  - Optimized threshold: 0.30\n",
      "\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 11. SAVE ALL METRICS AND METADATA\n",
    "# ===================================================================\n",
    "all_metrics = {\n",
    "    \"initial\": {\n",
    "        \"train\": metrics_train,\n",
    "        \"val\": metrics_val,\n",
    "        \"test\": metrics_test,\n",
    "    },\n",
    "    \"optimized\": {\n",
    "        \"val\": metrics_val_opt,\n",
    "        \"test\": metrics_test_opt,\n",
    "        \"best_threshold\": float(best_threshold)\n",
    "    },\n",
    "    \"cv_summary\": cv_summary,\n",
    "}\n",
    "\n",
    "with open(os.path.join(ARTIFACT_DIR, \"metrics.json\"), \"w\") as f:\n",
    "    json.dump(all_metrics, f, indent=4)\n",
    "\n",
    "meta = {\n",
    "    \"dataset_path\": DATA_PATH,\n",
    "    \"n_samples\": int(df.shape[0]),\n",
    "    \"n_features\": int(df.shape[1] - 1),\n",
    "    \"target_column\": TARGET_COL,\n",
    "    \"class_names\": class_names,\n",
    "    \"numeric_features\": numeric_features,\n",
    "    \"categorical_features\": categorical_features,\n",
    "    \"ensemble_type\": \"VotingClassifier (soft voting) with SMOTE\",\n",
    "    \"models\": [\"Deep MLP (512,256,128,64,32)\", \"XGBoost\", \"Random Forest\"],\n",
    "    \"mlp_hidden_layers\": [512, 256, 128, 64, 32],\n",
    "    \"xgb_n_estimators\": int(xgb_clf.n_estimators),\n",
    "    \"xgb_max_depth\": int(xgb_clf.max_depth),\n",
    "    \"rf_n_estimators\": int(rf_clf.n_estimators),\n",
    "    \"random_state\": RANDOM_STATE,\n",
    "    \"test_size\": TEST_SIZE,\n",
    "    \"val_size\": VAL_SIZE,\n",
    "    \"created_at\": datetime.now().isoformat(),\n",
    "}\n",
    "\n",
    "with open(os.path.join(ARTIFACT_DIR, \"metadata.json\"), \"w\") as f:\n",
    "    json.dump(meta, f, indent=4)\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"PIPELINE COMPLETE\")\n",
    "print(\"=\"*70)\n",
    "print(f\"\\n✅ All artifacts saved to: {ARTIFACT_DIR}\")\n",
    "print(\"\\nSaved files:\")\n",
    "print(\"  - ensemble_pipeline.joblib (trained model)\")\n",
    "print(\"  - label_encoder.joblib\")\n",
    "print(\"  - metrics.json (all performance metrics)\")\n",
    "print(\"  - metadata.json\")\n",
    "print(\"  - confusion matrices (PNG)\")\n",
    "print(\"  - EDA plots (PNG)\")\n",
    "print(\"  - train/val/test splits (CSV)\")\n",
    "print(\"\\nEnsemble combines:\")\n",
    "print(\"  - Deep MLP: 5 layers (512→256→128→64→32)\")\n",
    "print(\"  - XGBoost: 500 trees with class balancing\")\n",
    "print(\"  - Random Forest: 300 trees with balanced weights\")\n",
    "print(\"  - SMOTE oversampling for training balance\")\n",
    "print(f\"  - Optimized threshold: {best_threshold:.2f}\")\n",
    "print(\"\\n\" + \"=\"*70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "445e006c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "GENERATING PERFORMANCE PLOTS\n",
      "======================================================================\n",
      "✓ Saved cv_metrics_comparison.png\n",
      "✓ Saved metrics_comparison_all_splits.png\n",
      "✓ Saved initial_vs_optimized.png\n",
      "✓ Saved false_positives_negatives.png\n",
      "✓ Saved roc_curve_test.png\n",
      "✓ Saved precision_recall_curve_test.png\n",
      "✓ Saved sensitivity_specificity.png\n",
      "\n",
      "\n",
      "PATIENT TREATMENT CLASSIFICATION - ENSEMBLE MODEL\n",
      "==================================================\n",
      "\n",
      "Dataset: C:\\PERSONAL\\PATIENT TREATMENT CLASSIFICATION\\DATASET.csv\n",
      "Samples: 4412\n",
      "Features: 10\n",
      "Target: SOURCE\n",
      "Classes: ['in', 'out']\n",
      "\n",
      "ARCHITECTURE\n",
      "------------\n",
      "- Deep MLP: 5 layers (512, 256, 128, 64, 32)\n",
      "- XGBoost: 500 trees, max_depth=4, scale_pos_weight=0.68\n",
      "- Random Forest: 300 trees, class_weight='balanced'\n",
      "- Ensemble: Soft voting with weights [1.5, 2.0, 1.0]\n",
      "- Data balancing: SMOTE oversampling\n",
      "\n",
      "PERFORMANCE SUMMARY\n",
      "-------------------\n",
      "Test Set (Initial, threshold=0.5):\n",
      "  Accuracy:  0.7271\n",
      "  Precision: 0.7902\n",
      "  Recall:    0.7376\n",
      "  F1 Score:  0.7630\n",
      "  ROC AUC:   0.8091\n",
      "  False Positives: 103\n",
      "  False Negatives: 138\n",
      "\n",
      "Test Set (Optimized, threshold=0.30):\n",
      "  Accuracy:  0.7463\n",
      "  Precision: 0.7412\n",
      "  Recall:    0.8821\n",
      "  F1 Score:  0.8056\n",
      "  ROC AUC:   0.8091\n",
      "  Sensitivity: 0.8821\n",
      "  Specificity: 0.5462\n",
      "  False Positives: 162\n",
      "  False Negatives: 62\n",
      "\n",
      "Cross-Validation (5-fold):\n",
      "  Mean Val Accuracy: 0.7385 ± 0.0072\n",
      "  Mean Val F1:       0.7764 ± 0.0102\n",
      "  Mean Val ROC AUC:  0.8023 ± 0.0068\n",
      "\n",
      "Generated: 2025-12-15 23:31:16\n",
      "\n",
      "✓ Saved performance_summary.txt\n",
      "\n",
      "======================================================================\n",
      "ALL PLOTS GENERATED\n",
      "======================================================================\n",
      "\n",
      "Generated visualizations:\n",
      "  1. cv_metrics_comparison.png\n",
      "  2. metrics_comparison_all_splits.png\n",
      "  3. initial_vs_optimized.png\n",
      "  4. false_positives_negatives.png\n",
      "  5. roc_curve_test.png\n",
      "  6. precision_recall_curve_test.png\n",
      "  7. sensitivity_specificity.png\n",
      "  8. performance_summary.txt\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# ===================================================================\n",
    "# 12. PLOT TRAINING METRICS AND PERFORMANCE VISUALIZATIONS\n",
    "# ===================================================================\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"GENERATING PERFORMANCE PLOTS\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 12a. Cross-Validation Scores Comparison\n",
    "# -------------------------------------------------------------------\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
    "\n",
    "# Accuracy\n",
    "axes[0].bar(['Train', 'Val'], \n",
    "            [cv_summary['mean_train_accuracy'], cv_summary['mean_val_accuracy']],\n",
    "            yerr=[cv_summary['std_train_accuracy'], cv_summary['std_val_accuracy']],\n",
    "            capsize=5, color=['#2ecc71', '#3498db'])\n",
    "axes[0].set_ylabel('Accuracy')\n",
    "axes[0].set_title('Cross-Validation Accuracy')\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# F1 Score\n",
    "axes[1].bar(['Train', 'Val'], \n",
    "            [cv_summary['mean_train_f1'], cv_summary['mean_val_f1']],\n",
    "            yerr=[cv_summary['std_train_f1'], cv_summary['std_val_f1']],\n",
    "            capsize=5, color=['#2ecc71', '#3498db'])\n",
    "axes[1].set_ylabel('F1 Score')\n",
    "axes[1].set_title('Cross-Validation F1 Score')\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# ROC AUC\n",
    "axes[2].bar(['Val'], \n",
    "            [cv_summary['mean_val_roc_auc']],\n",
    "            yerr=[cv_summary['std_val_roc_auc']],\n",
    "            capsize=5, color=['#3498db'])\n",
    "axes[2].set_ylabel('ROC AUC')\n",
    "axes[2].set_title('Cross-Validation ROC AUC')\n",
    "axes[2].set_ylim([0, 1])\n",
    "axes[2].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ARTIFACT_DIR, \"cv_metrics_comparison.png\"), dpi=150)\n",
    "plt.close()\n",
    "print(\"✓ Saved cv_metrics_comparison.png\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 12b. Train/Val/Test Performance Comparison\n",
    "# -------------------------------------------------------------------\n",
    "splits = ['Train', 'Val', 'Test']\n",
    "accuracies = [metrics_train['accuracy'], metrics_val['accuracy'], metrics_test['accuracy']]\n",
    "precisions = [metrics_train['precision'], metrics_val['precision'], metrics_test['precision']]\n",
    "recalls = [metrics_train['recall'], metrics_val['recall'], metrics_test['recall']]\n",
    "f1s = [metrics_train['f1'], metrics_val['f1'], metrics_test['f1']]\n",
    "aucs = [metrics_train['roc_auc'], metrics_val['roc_auc'], metrics_test['roc_auc']]\n",
    "\n",
    "x = np.arange(len(splits))\n",
    "width = 0.15\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "ax.bar(x - 2*width, accuracies, width, label='Accuracy', color='#3498db')\n",
    "ax.bar(x - width, precisions, width, label='Precision', color='#2ecc71')\n",
    "ax.bar(x, recalls, width, label='Recall', color='#e74c3c')\n",
    "ax.bar(x + width, f1s, width, label='F1 Score', color='#f39c12')\n",
    "ax.bar(x + 2*width, aucs, width, label='ROC AUC', color='#9b59b6')\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Model Performance Across Splits')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(splits)\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 1])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ARTIFACT_DIR, \"metrics_comparison_all_splits.png\"), dpi=150)\n",
    "plt.close()\n",
    "print(\"✓ Saved metrics_comparison_all_splits.png\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 12c. Optimized vs Initial Performance (Val and Test)\n",
    "# -------------------------------------------------------------------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# Validation\n",
    "val_metrics_initial = [metrics_val['accuracy'], metrics_val['precision'], \n",
    "                       metrics_val['recall'], metrics_val['f1'], metrics_val['roc_auc']]\n",
    "val_metrics_opt = [metrics_val_opt['accuracy'], metrics_val_opt['precision'], \n",
    "                   metrics_val_opt['recall'], metrics_val_opt['f1'], metrics_val_opt['roc_auc']]\n",
    "\n",
    "metric_names = ['Accuracy', 'Precision', 'Recall', 'F1', 'AUC']\n",
    "x_pos = np.arange(len(metric_names))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x_pos - width/2, val_metrics_initial, width, \n",
    "            label='Initial (thresh=0.5)', color='#3498db')\n",
    "axes[0].bar(x_pos + width/2, val_metrics_opt, width, \n",
    "            label=f'Optimized (thresh={best_threshold:.2f})', color='#2ecc71')\n",
    "axes[0].set_ylabel('Score')\n",
    "axes[0].set_title('Validation Set: Initial vs Optimized')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(metric_names, rotation=45)\n",
    "axes[0].legend()\n",
    "axes[0].set_ylim([0, 1])\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Test\n",
    "test_metrics_initial = [metrics_test['accuracy'], metrics_test['precision'], \n",
    "                        metrics_test['recall'], metrics_test['f1'], metrics_test['roc_auc']]\n",
    "test_metrics_opt = [metrics_test_opt['accuracy'], metrics_test_opt['precision'], \n",
    "                    metrics_test_opt['recall'], metrics_test_opt['f1'], metrics_test_opt['roc_auc']]\n",
    "\n",
    "axes[1].bar(x_pos - width/2, test_metrics_initial, width, \n",
    "            label='Initial (thresh=0.5)', color='#3498db')\n",
    "axes[1].bar(x_pos + width/2, test_metrics_opt, width, \n",
    "            label=f'Optimized (thresh={best_threshold:.2f})', color='#2ecc71')\n",
    "axes[1].set_ylabel('Score')\n",
    "axes[1].set_title('Test Set: Initial vs Optimized')\n",
    "axes[1].set_xticks(x_pos)\n",
    "axes[1].set_xticklabels(metric_names, rotation=45)\n",
    "axes[1].legend()\n",
    "axes[1].set_ylim([0, 1])\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ARTIFACT_DIR, \"initial_vs_optimized.png\"), dpi=150)\n",
    "plt.close()\n",
    "print(\"✓ Saved initial_vs_optimized.png\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 12d. False Positives and False Negatives Comparison\n",
    "# -------------------------------------------------------------------\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Initial\n",
    "splits_fp_fn = ['Train', 'Val', 'Test']\n",
    "fps_initial = [metrics_train['false_positives'], \n",
    "               metrics_val['false_positives'], \n",
    "               metrics_test['false_positives']]\n",
    "fns_initial = [metrics_train['false_negatives'], \n",
    "               metrics_val['false_negatives'], \n",
    "               metrics_test['false_negatives']]\n",
    "\n",
    "x_pos = np.arange(len(splits_fp_fn))\n",
    "width = 0.35\n",
    "\n",
    "axes[0].bar(x_pos - width/2, fps_initial, width, label='False Positives', color='#e74c3c')\n",
    "axes[0].bar(x_pos + width/2, fns_initial, width, label='False Negatives', color='#f39c12')\n",
    "axes[0].set_ylabel('Count')\n",
    "axes[0].set_title('Errors - Initial (threshold=0.5)')\n",
    "axes[0].set_xticks(x_pos)\n",
    "axes[0].set_xticklabels(splits_fp_fn)\n",
    "axes[0].legend()\n",
    "axes[0].grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Optimized (Val and Test only)\n",
    "splits_opt = ['Val', 'Test']\n",
    "fps_opt = [metrics_val_opt['false_positives'], metrics_test_opt['false_positives']]\n",
    "fns_opt = [metrics_val_opt['false_negatives'], metrics_test_opt['false_negatives']]\n",
    "\n",
    "x_pos_opt = np.arange(len(splits_opt))\n",
    "\n",
    "axes[1].bar(x_pos_opt - width/2, fps_opt, width, label='False Positives', color='#e74c3c')\n",
    "axes[1].bar(x_pos_opt + width/2, fns_opt, width, label='False Negatives', color='#f39c12')\n",
    "axes[1].set_ylabel('Count')\n",
    "axes[1].set_title(f'Errors - Optimized (threshold={best_threshold:.2f})')\n",
    "axes[1].set_xticks(x_pos_opt)\n",
    "axes[1].set_xticklabels(splits_opt)\n",
    "axes[1].legend()\n",
    "axes[1].grid(axis='y', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ARTIFACT_DIR, \"false_positives_negatives.png\"), dpi=150)\n",
    "plt.close()\n",
    "print(\"✓ Saved false_positives_negatives.png\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 12e. ROC Curve (Test Set)\n",
    "# -------------------------------------------------------------------\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "y_test_proba = ensemble_pipeline.predict_proba(X_test)[:, 1]\n",
    "fpr, tpr, thresholds_roc = roc_curve(y_test, y_test_proba)\n",
    "roc_auc_val = auc(fpr, tpr)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='#2ecc71', lw=2, \n",
    "         label=f'ROC curve (AUC = {roc_auc_val:.4f})')\n",
    "plt.plot([0, 1], [0, 1], color='#95a5a6', lw=2, linestyle='--', label='Random')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Test Set')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ARTIFACT_DIR, \"roc_curve_test.png\"), dpi=150)\n",
    "plt.close()\n",
    "print(\"✓ Saved roc_curve_test.png\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 12f. Precision-Recall Curve (Test Set)\n",
    "# -------------------------------------------------------------------\n",
    "from sklearn.metrics import precision_recall_curve, average_precision_score\n",
    "\n",
    "precision_curve, recall_curve, _ = precision_recall_curve(y_test, y_test_proba)\n",
    "avg_precision = average_precision_score(y_test, y_test_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(recall_curve, precision_curve, color='#3498db', lw=2,\n",
    "         label=f'PR curve (AP = {avg_precision:.4f})')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.title('Precision-Recall Curve - Test Set')\n",
    "plt.legend(loc=\"lower left\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ARTIFACT_DIR, \"precision_recall_curve_test.png\"), dpi=150)\n",
    "plt.close()\n",
    "print(\"✓ Saved precision_recall_curve_test.png\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 12g. Per-Class Performance (Sensitivity and Specificity)\n",
    "# -------------------------------------------------------------------\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "splits_sens_spec = ['Train', 'Val (init)', 'Val (opt)', 'Test (init)', 'Test (opt)']\n",
    "sensitivities = [\n",
    "    metrics_train['sensitivity'],\n",
    "    metrics_val['sensitivity'],\n",
    "    metrics_val_opt['sensitivity'],\n",
    "    metrics_test['sensitivity'],\n",
    "    metrics_test_opt['sensitivity']\n",
    "]\n",
    "specificities = [\n",
    "    metrics_train['specificity'],\n",
    "    metrics_val['specificity'],\n",
    "    metrics_val_opt['specificity'],\n",
    "    metrics_test['specificity'],\n",
    "    metrics_test_opt['specificity']\n",
    "]\n",
    "\n",
    "x_pos = np.arange(len(splits_sens_spec))\n",
    "width = 0.35\n",
    "\n",
    "ax.bar(x_pos - width/2, sensitivities, width, \n",
    "       label=f\"Sensitivity ('{class_names[1]}' recall)\", color='#9b59b6')\n",
    "ax.bar(x_pos + width/2, specificities, width, \n",
    "       label=f\"Specificity ('{class_names[0]}' recall)\", color='#1abc9c')\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Per-Class Performance: Sensitivity & Specificity')\n",
    "ax.set_xticks(x_pos)\n",
    "ax.set_xticklabels(splits_sens_spec, rotation=30, ha='right')\n",
    "ax.legend()\n",
    "ax.set_ylim([0, 1])\n",
    "ax.grid(axis='y', alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.savefig(os.path.join(ARTIFACT_DIR, \"sensitivity_specificity.png\"), dpi=150)\n",
    "plt.close()\n",
    "print(\"✓ Saved sensitivity_specificity.png\")\n",
    "\n",
    "# -------------------------------------------------------------------\n",
    "# 12h. Summary Report\n",
    "# -------------------------------------------------------------------\n",
    "summary_text = f\"\"\"\n",
    "PATIENT TREATMENT CLASSIFICATION - ENSEMBLE MODEL\n",
    "==================================================\n",
    "\n",
    "Dataset: {DATA_PATH}\n",
    "Samples: {df.shape[0]}\n",
    "Features: {df.shape[1] - 1}\n",
    "Target: {TARGET_COL}\n",
    "Classes: {class_names}\n",
    "\n",
    "ARCHITECTURE\n",
    "------------\n",
    "- Deep MLP: 5 layers (512, 256, 128, 64, 32)\n",
    "- XGBoost: 500 trees, max_depth=4, scale_pos_weight={scale_weight:.2f}\n",
    "- Random Forest: 300 trees, class_weight='balanced'\n",
    "- Ensemble: Soft voting with weights [1.5, 2.0, 1.0]\n",
    "- Data balancing: SMOTE oversampling\n",
    "\n",
    "PERFORMANCE SUMMARY\n",
    "-------------------\n",
    "Test Set (Initial, threshold=0.5):\n",
    "  Accuracy:  {metrics_test['accuracy']:.4f}\n",
    "  Precision: {metrics_test['precision']:.4f}\n",
    "  Recall:    {metrics_test['recall']:.4f}\n",
    "  F1 Score:  {metrics_test['f1']:.4f}\n",
    "  ROC AUC:   {metrics_test['roc_auc']:.4f}\n",
    "  False Positives: {metrics_test['false_positives']}\n",
    "  False Negatives: {metrics_test['false_negatives']}\n",
    "\n",
    "Test Set (Optimized, threshold={best_threshold:.2f}):\n",
    "  Accuracy:  {metrics_test_opt['accuracy']:.4f}\n",
    "  Precision: {metrics_test_opt['precision']:.4f}\n",
    "  Recall:    {metrics_test_opt['recall']:.4f}\n",
    "  F1 Score:  {metrics_test_opt['f1']:.4f}\n",
    "  ROC AUC:   {metrics_test_opt['roc_auc']:.4f}\n",
    "  Sensitivity: {metrics_test_opt['sensitivity']:.4f}\n",
    "  Specificity: {metrics_test_opt['specificity']:.4f}\n",
    "  False Positives: {metrics_test_opt['false_positives']}\n",
    "  False Negatives: {metrics_test_opt['false_negatives']}\n",
    "\n",
    "Cross-Validation (5-fold):\n",
    "  Mean Val Accuracy: {cv_summary['mean_val_accuracy']:.4f} ± {cv_summary['std_val_accuracy']:.4f}\n",
    "  Mean Val F1:       {cv_summary['mean_val_f1']:.4f} ± {cv_summary['std_val_f1']:.4f}\n",
    "  Mean Val ROC AUC:  {cv_summary['mean_val_roc_auc']:.4f} ± {cv_summary['std_val_roc_auc']:.4f}\n",
    "\n",
    "Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n",
    "\"\"\"\n",
    "\n",
    "with open(os.path.join(ARTIFACT_DIR, \"performance_summary.txt\"), \"w\") as f:\n",
    "    f.write(summary_text)\n",
    "\n",
    "print(\"\\n\" + summary_text)\n",
    "print(\"✓ Saved performance_summary.txt\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ALL PLOTS GENERATED\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nGenerated visualizations:\")\n",
    "print(\"  1. cv_metrics_comparison.png\")\n",
    "print(\"  2. metrics_comparison_all_splits.png\")\n",
    "print(\"  3. initial_vs_optimized.png\")\n",
    "print(\"  4. false_positives_negatives.png\")\n",
    "print(\"  5. roc_curve_test.png\")\n",
    "print(\"  6. precision_recall_curve_test.png\")\n",
    "print(\"  7. sensitivity_specificity.png\")\n",
    "print(\"  8. performance_summary.txt\")\n",
    "print(\"=\"*70)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
